\documentclass[12pt,english]{article}
\usepackage{geometry}
\geometry{a4paper,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\setlength{\parskip}{\bigskipamount}
\setlength{\parindent}{0pt}
\usepackage{setspace}
\onehalfspacing
\usepackage{babel}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{amsmath}

\begin{document}

%%%%%%%%%%%%%
% TITLE/TOC %
%%%%%%%%%%%%%

\title{Advanced Operating Systems - System Documentation}
\author{\textbf{Group 3} \\ David Terei, Benjamin Kalman}
\maketitle

\tableofcontents{}

%%%%%%%%
% TODO %
%%%%%%%%

\newpage{}
\section{TODO}

\begin{itemize}
\item 3: system call interface
\item 4: NFS
\item 5: demand paging
\item 6: timer driver?
\item 7: process management
\item 8: ELF loading
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%
% MEMORY MANAGEMENT %
%%%%%%%%%%%%%%%%%%%%%

\section{Memory management}

\subsection{Page table structure}

The page table is a lazy, two level page table.  

\begin{verbatim}
#define PAGEWORDS (PAGESIZE / sizeof(L4_Word_t))

typedef struct  {
    L4_Word_t pages[PAGEWORDS];
} Pagetable2;

typedef struct {
    Pagetable2 *pages2[PAGEWORDS];
} Pagetable1;
\end{verbatim}

\subsection{Address location}

To locate the 32 bit virtual address \texttt{v}, the highest 12 bits are used to index in to the first level of the table (\texttt{Pagetable1}) in order to find the corresponding second level struct.  If this is \texttt{NULL}, this second level is dynamically created.  The middle 12 bits of \texttt{v} are then used to index in to this second level, locating the relevant entry \texttt{e}.  Note that the lowest 12 bits of \texttt{v} are not needed for page table addressing.

The high 24 bits of \texttt{e} give the \emph{page aligned} physical address\footnote{In fact, ppage} of what \texttt{v} is mapped to.  The lower 12 bits are then used to maintain status bits, for example the reference bit and swapped status.

\subsection{Region management}

Regions are managed with a linked list of \texttt{Region} structs.

\begin{verbatim}
struct Region_t {
    region_type type;
    uintptr_t base;
    unsigned int size;
    unsigned int filesize;
    int rights;
    int mapDirectly;
    Swapfile *elffile;
};
\end{verbatim}

\begin{itemize}
\item \texttt{type} is used to differentiate between the stack, heap, and other regions.  It is important to know which region is the heap in order for the \texttt{moremem} system call to function, see Section \ref{sub:moremem}.
\item \texttt{base}, \texttt{size}, and \texttt{rights} are the self explanitory.
\item \texttt{filesize} is the size of the region as it appears on file, important for ELF loading.
\item \texttt{mapDirectly} is solely important for programs loaded from bootinfo, which require their text and data sections to be 1:1 mapped to physical memory.
\item \texttt{elffile} is the ELF file the region is located on, represented as a swap file (see Section \ref{sub:demand_paging}).
\end{itemize}

\subsection{Page fault mechanism}

The page fault mechanism is as follows:
\begin{enumerate}
\item The faulting region is located.  If no region is found, or if the type of access which causes the fault (read/write/exec) is illegal, the faulting process is killed (see Section \ref{sub:process_delete}).
\item If the faulting address is on disk, the page fault is added to the ``blocking'' queue to be dealt with asynchronously.  Note that in this case the faulting process is not woken up.
\item If the faulting address needs to be 1:1 mapped, the mapping is immediately made.
\item Otherwise, a frame attempts to be allocated for the fault.  If there are no free frames, the fault is again delayed for later.
\item Assuming nothing is delayed, the reference bit is set, the mapping made, and the faulting process woken.
\end{enumerate}

Specific discussion of the asynchronous paging mechanism, see Section \ref{sub:demand_paging}.

\subsection{Kernel memory}

The kernel is designed in such a way that it assumes it can always allocate frames for itself, a problem when userspace programs are allocated frames from the same pool.  To solve this, the number of userspace frames are artificially limited to a constant amount (\texttt{FRAME\_ALLOC\_LIMIT}), chosen conservatively enough to ensure the kernel will never run out of memory, but generous enough for the limit to only be observable when memory is deliberately thrashed.

This policy has several advantages.  The kernel can run out of physical memory, not virtual, and it requires no complicated IO in order to safely do so.  The kernel can easily allocate temporary frames, useful when creating processes and for ``pinning'' frames to ensure fairness when swapping out.  This also makes testing the memory management easy, by setting the alloc limit very low.

\subsection{Pager thread}

It is worth noting that there are no kernel threads, with the exception of those used for network, initialisation, and \emph{paging}.

The decision to put the pager in its own thread was made for the following reasons:
\begin{itemize}
\item The operations of the pager and the root server are largely\footnote{The root server and pager share a single data structure, the ``copy buffer''.  See Section \ref{sub:system_call_interface}} orthogonal, so operations in the pager can happen simultaneously with the rootserver, (theoretically) without race conditions.
\item With its own syscall loop independent from the root servers, the pager is able to IPC the root server.  This is most used in order to use the generic IO system calls, rather than an additional in-kernel interface.  Indeed, this does require that special ``non blocking'' system calls are able to be made, such that the root server's replies arrive in the pager's syscall loop.  Overall, this is used to implement the asynchronous IO used in the pager.
\item It is necessary for the pager to be able to access all of physical memory, most notably for copyin/copyout (see Section \ref{sub:copyin_copyout}).  Without careful management (or a brute force approach), this would cause root task pagefaults.  Instead, this allows the root task to act as the pager for the pager and manage memory accordingly.
\end{itemize}

Several other types of system calls are also handled by the pager, including all process management system calls.  This is necessary as process management is closely linked to memory management, and race conditions arise otherwise.  The division of system call work is discussed further in Section \ref{sub:system_call_interface}.

\subsection{Demand paging} \label{sub:demand_paging}

The process of demand paging is slightly complicated, and encompasses nearly all asynchronous requests in the pager, including the lazy ELF loading.  For now however, just \emph{swapping in} and \emph{swapping out} will be covered, with ELF loading described in Section \ref{sub:elf_loading}.

\subsubsection{Delayed page faults}

As described in the page fault algorithm, there are two cases when a page fault is delayed: if the page is on disk, or if there are no free frames.  These are simply delayed as a ``pager request'' and added to a queue of asynchronous (blocking) requests to be dealt with sequentially.

This asynchronous queue is managed as follows:
\begin{enumerate}
\item Upon adding a request to the queue, if it is currently empty the request at the head is immediately started.
\item When started, the original page fault request is attempted again.  In the meantime, a frame might have been freed (for example, if a process died) or the frame might have already been swapped in (for example, if we had implemented shared memory).
\item Assuming the page fault must again block, a sequence of callbacks is immediately started.  A decision is made: if the request simply required a free frame, a \emph{swap out} request is made.  Otherwise, a \emph{swap in} request is made.  These are each described separately below.
\item In either case, upon finishin the page request is dequeued.  If the asynchronous request queue is not empty then the next one started.
\end{enumerate}

The sequential nature of the blocking requests is so that all replies from the root server are unambiguous, and indeed happen sequentially such that continuation state is simply a counter.  There is no blocking, as while waiting for a reply from the root server all other requests to the pager.  Incidentally, this also does not introduce artificial overhead as all asynchronous operations involve NFS, which has a fixed bandwidth and attempting multiple requests simultaneously offers no advantage.

\subsubsection{Swapping out}

Swapping a page out involves the following steps:
\begin{itemize}
\item A page is chosen to swap out using the second chance algorithm.  The algorithm is well known so not worth explaining here, but as as reminder the reference bit is kept in the lower 12 bits of every page table entry.  When this bit is unset, the page is also unmapped so that a fault will occur when (or if) later referenced.
\item A \emph{swap out request} is pushed to the heap of the request queue, then the request started.
\item A slot in the swap file is allocated in a process similar to frame allocation.
\item The swap out request will open (non blocking) the relevant swap file given in the region list (although currently always ``.swap'').  This sets of a chain of continuations which open, lseek, write, then close the file in sequential order.
\item On finishing: the frame is freed, swap out request dequeued, and the next request run.  This will either be a page fault (which is now guaranteed to find a frame) or a swap in request (likewise, but discussed below).
\end{itemize}

\subsubsection{Swapping in}

Swapping in a page is slightly more complicated than swapping in a page:
\begin{itemize}
\item The region list is searched for the faulting 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%
% SYSTEM CALL INTERFACE %
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{System call interface}

\subsection{Copyin/Copyout}

%%%%%%%
% ETC %
%%%%%%%

\newpage{}
\section{Etc}

\end{document}

